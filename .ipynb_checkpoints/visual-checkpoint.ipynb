{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import model\n",
    "import torch\n",
    "import dataset\n",
    "import model\n",
    "import math\n",
    "import numpy as np\n",
    "import utility\n",
    "import os\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_reg_model(model, test_dataset, batch_size=50, criterion=None, num_rects=4, screen_w=640, screen_h=480):\n",
    "    model.eval()\n",
    "    \n",
    "    if criterion is None:\n",
    "        criterion = torch.nn.MSELoss().cuda()\n",
    "\n",
    "    print(\"CURRENT MODEL seq_len: {}\".format(test_dataset.seq_len))\n",
    "    print(\"CURRENT MODEL: {}\".format(model.__class__.__name__))\n",
    "    print(\"CURRENT DATASET SIZE: {}\".format(test_dataset.__len__()))\n",
    "    print(\"CURRENT NUM RECTS: {}\".format(num_rects))\n",
    "    \n",
    "    test_loader = torch.utils.data.DataLoader(dataset=test_dataset,\n",
    "                                               batch_size=batch_size,\n",
    "                                               shuffle=True)\n",
    "\n",
    "    min_error = 999999\n",
    "    max_error = 0\n",
    "    sum_error = 0\n",
    "    count_error = 0\n",
    "    errors = np.zeros(test_dataset.__len__())\n",
    "\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    \n",
    "    min_loss = 999999\n",
    "    max_loss = 0\n",
    "    sum_loss = 0\n",
    "    count_loss = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for i, (eye_left, eye_right, face, pos) in enumerate(test_loader):\n",
    "            eye_left = eye_left.to(device)\n",
    "            eye_right = eye_right.to(device)\n",
    "            face = face.to(device)\n",
    "            pos = pos.to(device)\n",
    "\n",
    "            # Forward pass\n",
    "            out = model(eye_left, eye_right, face)\n",
    "            pos = pos[:, -1, :]\n",
    "            loss = criterion(out, pos)\n",
    "\n",
    "            out = out.cpu().detach().numpy()\n",
    "            pos = pos.cpu().numpy()\n",
    "\n",
    "            for b in range(pos.shape[0]):\n",
    "                o = out[b]\n",
    "                p = pos[b]\n",
    "\n",
    "                error = math.sqrt((o[0] - p[0])**2 + (o[1] - p[1])**2)\n",
    "\n",
    "                if error < min_error:\n",
    "                    min_error = error\n",
    "                if error > max_error:\n",
    "                    max_error = error\n",
    "                sum_error += error\n",
    "\n",
    "                errors[count_error] = error\n",
    "                \n",
    "                o_x = math.ceil((o[0]) / (screen_w / num_rects))\n",
    "                o_y = math.ceil((o[1]) / (screen_h / num_rects))\n",
    "\n",
    "                p_x = math.ceil((p[0]) / (screen_w / num_rects))\n",
    "                p_y = math.ceil((p[1]) / (screen_h / num_rects))\n",
    "\n",
    "                \n",
    "                if ((p_y - 1) * num_rects + (p_x - 1)) == ((o_y - 1) * num_rects + (o_x - 1)):\n",
    "                    correct += 1\n",
    "                    \n",
    "                total += 1\n",
    "                \n",
    "                count_error += 1\n",
    "\n",
    "            if loss.item() < min_loss:\n",
    "                min_loss = loss.item()\n",
    "            if loss.item() > max_loss:\n",
    "                max_loss = loss.item()\n",
    "            sum_loss += loss.item()\n",
    "            count_loss += 1\n",
    "\n",
    "        print('MIN MSELoss: {} '.format(min_loss))\n",
    "        print('MAX MSELoss: {} '.format(max_loss))\n",
    "        print('AVG MSELoss: {}'.format(sum_loss / count_loss))\n",
    "\n",
    "        print('MIN error: {} '.format(min_error))\n",
    "        print('MAX error: {} '.format(max_error))\n",
    "        print('AVG error: {}'.format(sum_error / count_error))\n",
    "        print('MEAD error: {}'.format(np.median(errors)))\n",
    "\n",
    "    print('Accuracy : %d %%' % (100 * correct / total))\n",
    "    return test_dataset.__len__(), min_error, max_error, (sum_error / count_error), (np.median(errors)), errors\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_classifire_model(model, test_dataset, batch_size=50):\n",
    "    model.eval()  \n",
    "    \n",
    "    criterion = torch.nn.BCELoss().cuda()\n",
    "\n",
    "    print(\"CURRENT MODEL seq_len: {}\".format(test_dataset.seq_len))\n",
    "    print(\"CURRENT MODEL: {}\".format(model.__class__.__name__))\n",
    "    print(\"CURRENT DATASET SIZE: {}\".format(test_dataset.__len__()))\n",
    "    print(\"CURRENT NUM RECTS: {}\".format(num_rects))\n",
    "\n",
    "    test_loader = torch.utils.data.DataLoader(dataset=test_dataset,\n",
    "                                               batch_size=batch_size,\n",
    "                                               shuffle=True)\n",
    "\n",
    "    correct = 0\n",
    "    total = 0\n",
    "\n",
    "    min_loss = 999999\n",
    "    max_loss = 0\n",
    "    sum_loss = 0\n",
    "    count_loss = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for i, (eye_left, eye_right, face, pos) in enumerate(test_loader):\n",
    "            eye_left = eye_left.to(device)\n",
    "            eye_right = eye_right.to(device)\n",
    "            face = face.to(device)\n",
    "            pos = pos.to(device)\n",
    "\n",
    "            # Forward pass\n",
    "            out = model(eye_left, eye_right, face)\n",
    "            loss = criterion(out, pos)\n",
    "\n",
    "            _, predicted = torch.max(out.data, 1)\n",
    "            _, pos = torch.max(pos.data, 1)\n",
    "            total += pos.size(0)\n",
    "            \n",
    "            correct += (predicted == pos).sum().item()\n",
    "            if loss.item() < min_loss:\n",
    "                min_loss = loss.item()\n",
    "            if loss.item() > max_loss:\n",
    "                max_loss = loss.item()\n",
    "            sum_loss += loss.item()\n",
    "            count_loss += 1\n",
    "\n",
    "        \n",
    "        print('MIN BCELoss: {} '.format(min_loss))\n",
    "        print('MAX BCELoss: {} '.format(max_loss))\n",
    "        print('AVG BCELoss: {}'.format(sum_loss / count_loss))\n",
    "        \n",
    "    print('Accuracy : %d %%' % (100 * correct / total))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "dataset_seq_len = 60\n",
    "\n",
    "batch_size = 10\n",
    "\n",
    "num_rects = 16\n",
    "seq_len = 8\n",
    "\n",
    "max_samples = 10770 \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LOAD MODEL: \n",
      "./models/EyeClassifierLSTM/model_10770_256_8.pth\n",
      "FOUND MODEL\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "./test/60/\n",
      "1178\n",
      "LOADING DATA...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "END LOAD DATA\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000\n",
      "[12.  2.  3.  3.  4.  3.  1. 14.  6.  2.  3.  4.  3.  3.  3.  7.  5.  9.\n",
      "  9.  3.  4.  8.  5.  7.  6.  3.  6.  4.  6.  4.  4.  4.  4.  4.  2. 11.\n",
      "  0.  4.  7.  2.  3.  4.  6.  6. 20. 10.  8.  2.  1.  7. 10.  4.  3.  2.\n",
      "  2.  4.  6.  5.  4.  4.  9.  7.  7.  3.  2.  8.  2.  7.  0.  1.  2.  2.\n",
      "  2.  2.  1.  2.  1.  6.  4.  2.  3.  2. 10.  1.  2.  2.  1.  2.  2.  1.\n",
      "  2.  2.  2.  4.  4.  4.  3.  2.  7.  5.  1.  1.  0.  2.  5.  1.  0.  0.\n",
      " 14.  2.  7.  3.  6.  1.  3.  0.  1.  2.  1.  1.  7.  3.  2.  3.  2.  5.\n",
      "  1.  3.  3. 14.  2.  5.  2.  2.  0.  1.  2.  2.  5.  2.  6.  6.  5.  7.\n",
      "  3.  3.  2.  6.  1.  3.  2.  1.  2.  2.  2.  2.  3.  4.  2.  2.  7.  3.\n",
      "  3.  7.  4.  3.  0.  0. 10.  1.  3. 10.  5.  8.  5.  1.  3.  2.  6.  2.\n",
      "  3.  0.  3.  2.  1.  4.  3.  5.  5.  4.  3.  4.  4.  7.  3.  1.  6.  3.\n",
      "  2.  3.  0.  1.  3.  2.  3.  5.  0.  3.  0.  3.  9.  5.  3.  3.  3.  3.\n",
      "  3.  5.  7.  4.  3.  2.  6.  1.  2.  5.  8.  6.  3.  4.  4.  4.  3.  1.\n",
      "  4.  4.  2.  3.  8.  2.  9.  4.  5.  0.  3.  5.  0.  9.  5.  9.  3.  5.\n",
      "  5.  2.  5. 26.]\n",
      "[14.  2.  5.  3.  4.  4.  1. 15. 12.  5.  4.  5.  4.  3.  3.  8.  6. 14.\n",
      " 10.  5.  5.  8.  5.  7.  7.  3.  7.  4.  6.  5.  6.  4.  4.  5.  2. 12.\n",
      "  0.  4.  7.  3.  3.  5.  7.  8. 25. 10. 10.  5.  3.  7. 10.  4.  3.  2.\n",
      "  3.  4.  7.  5.  4.  4. 11.  8.  8.  5.  2.  8.  2.  7.  1.  1.  5.  3.\n",
      "  2.  2.  2.  3.  1.  6.  4.  2.  3.  4. 10.  2.  4.  2.  3.  3.  2.  1.\n",
      "  2.  3.  3.  5.  5.  6.  3.  2.  9.  5.  2.  1.  0.  3.  7.  1.  0.  0.\n",
      " 18.  3. 10.  4.  6.  2.  3.  0.  1.  3.  2.  1. 10.  5.  4.  3.  2.  5.\n",
      "  1.  4.  4. 18.  2.  5.  3.  3.  0.  2.  2.  2.  5.  3.  6.  6.  5.  7.\n",
      "  3.  5.  2.  6.  1.  3.  2.  1.  6.  2.  2.  4.  3.  5.  2.  2.  7.  3.\n",
      "  4.  8.  4.  3.  0.  0. 11.  1.  3. 10.  5.  8.  6.  1.  3.  2.  6.  2.\n",
      "  5.  0.  3.  2.  2.  4.  3.  5.  5.  6.  4.  4.  5.  7.  4.  1.  7.  6.\n",
      "  2.  3.  0.  1.  3.  3.  3.  7.  2.  3.  0.  3.  9.  5.  3.  3.  3.  3.\n",
      "  3.  7.  7.  4.  3.  2.  7.  1.  7.  6.  9.  6.  3.  5.  4.  4.  4.  1.\n",
      "  4.  4.  2.  3.  9.  3. 10.  6.  5.  0.  3.  6.  1.  9.  6. 10.  4.  5.\n",
      "  8.  2.  7. 29.]\n",
      "CURRENT MODEL seq_len: 8\n",
      "CURRENT MODEL: EyeClassifierLSTM\n",
      "CURRENT DATASET SIZE: 1178\n",
      "CURRENT NUM RECTS: 16\n",
      "MIN BCELoss: 0.009856480173766613 \n",
      "MAX BCELoss: 0.031280212104320526 \n",
      "AVG BCELoss: 0.01887184205480804\n",
      "Accuracy : 25 %\n"
     ]
    }
   ],
   "source": [
    "m = utility.load_model('./models/EyeClassifierLSTM/model_{}_{}_{}.pth'.format(\n",
    "    max_samples, num_rects * num_rects, seq_len), \n",
    "                           device,\n",
    "                           model.EyeClassifierLSTM(num_rects * num_rects, seq_len))\n",
    "\n",
    "d = dataset.CDataset(num_rects=num_rects, seq_len=seq_len, dirname='./test')\n",
    "\n",
    "test_classifire_model(m, d, batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "./test/60/\n",
      "1178\n",
      "LOADING DATA...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LOAD MODEL: \n",
      "./models/TwoEyesLSTM/model_10770_8.pth\n",
      "FOUND MODEL\n",
      "0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "END LOAD DATA\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000\n",
      "CURRENT MODEL seq_len: 8\n",
      "CURRENT MODEL: TwoEyesLSTM\n",
      "CURRENT DATASET SIZE: 1178\n",
      "CURRENT NUM RECTS: 16\n",
      "MIN MSELoss: 1052.0064697265625 \n",
      "MAX MSELoss: 25174.990234375 \n",
      "AVG MSELoss: 4347.496573755297\n",
      "MIN error: 0.8911559400407107 \n",
      "MAX error: 688.4015269566917 \n",
      "AVG error: 69.50990516339161\n",
      "MEAD error: 54.345868681384616\n",
      "Accuracy : 8 %\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(1178,\n",
       " 0.8911559400407107,\n",
       " 688.4015269566917,\n",
       " 69.50990516339161,\n",
       " 54.345868681384616,\n",
       " array([14.4126884 , 72.09203549, 17.03490136, ..., 24.48682498,\n",
       "        21.04133028, 86.7435463 ]))"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m = utility.load_model('./models/TwoEyesLSTM/model_{}_{}.pth'.format(\n",
    "    max_samples, seq_len), \n",
    "            device,\n",
    "            model.TwoEyesLSTM(seq_len=seq_len))\n",
    "\n",
    "d = dataset.Dataset(seq_len=seq_len, dirname='./test')\n",
    "\n",
    "test_reg_model(m, d, batch_size=batch_size, num_rects=num_rects)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
