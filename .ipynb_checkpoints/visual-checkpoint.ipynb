{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import model\n",
    "import torch\n",
    "import dataset\n",
    "import model\n",
    "import math\n",
    "import numpy as np\n",
    "import utility\n",
    "import os\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_reg_model(model, test_dataset, batch_size=50, criterion=None, num_rects=4, screen_w=640, screen_h=480):\n",
    "    model.eval()\n",
    "    \n",
    "    if criterion is None:\n",
    "        criterion = torch.nn.MSELoss().cuda()\n",
    "\n",
    "    print(\"CURRENT MODEL seq_len: {}\".format(test_dataset.seq_len))\n",
    "    print(\"CURRENT MODEL: {}\".format(model.__class__.__name__))\n",
    "    print(\"CURRENT DATASET SIZE: {}\".format(test_dataset.__len__()))\n",
    "    print(\"CURRENT NUM RECTS: {}\".format(num_rects))\n",
    "    \n",
    "    test_loader = torch.utils.data.DataLoader(dataset=test_dataset,\n",
    "                                               batch_size=batch_size,\n",
    "                                               shuffle=True)\n",
    "\n",
    "    min_error = 999999\n",
    "    max_error = 0\n",
    "    sum_error = 0\n",
    "    count_error = 0\n",
    "    errors = np.zeros(test_dataset.__len__())\n",
    "\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    \n",
    "    min_loss = 999999\n",
    "    max_loss = 0\n",
    "    sum_loss = 0\n",
    "    count_loss = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for i, (eye_left, eye_right, face, pos) in enumerate(test_loader):\n",
    "            eye_left = eye_left.to(device)\n",
    "            eye_right = eye_right.to(device)\n",
    "            face = face.to(device)\n",
    "            pos = pos.to(device)\n",
    "\n",
    "            # Forward pass\n",
    "            out = model(eye_left, eye_right, face)\n",
    "            pos = pos[:, -1, :]\n",
    "            loss = criterion(out, pos)\n",
    "\n",
    "            out = out.cpu().detach().numpy()\n",
    "            pos = pos.cpu().numpy()\n",
    "\n",
    "            for b in range(pos.shape[0]):\n",
    "                o = out[b]\n",
    "                p = pos[b]\n",
    "\n",
    "                error = math.sqrt((o[0] - p[0])**2 + (o[1] - p[1])**2)\n",
    "\n",
    "                if error < min_error:\n",
    "                    min_error = error\n",
    "                if error > max_error:\n",
    "                    max_error = error\n",
    "                sum_error += error\n",
    "\n",
    "                errors[count_error] = error\n",
    "                \n",
    "                o_x = math.ceil((o[0]) / (screen_w / num_rects))\n",
    "                o_y = math.ceil((o[1]) / (screen_h / num_rects))\n",
    "\n",
    "                p_x = math.ceil((p[0]) / (screen_w / num_rects))\n",
    "                p_y = math.ceil((p[1]) / (screen_h / num_rects))\n",
    "\n",
    "                \n",
    "                if ((p_y - 1) * num_rects + (p_x - 1)) == ((o_y - 1) * num_rects + (o_x - 1)):\n",
    "                    correct += 1\n",
    "                    \n",
    "                total += 1\n",
    "                \n",
    "                count_error += 1\n",
    "\n",
    "            if loss.item() < min_loss:\n",
    "                min_loss = loss.item()\n",
    "            if loss.item() > max_loss:\n",
    "                max_loss = loss.item()\n",
    "            sum_loss += loss.item()\n",
    "            count_loss += 1\n",
    "\n",
    "        # print('MIN MSELoss: {} '.format(min_loss))\n",
    "        # print('MAX MSELoss: {} '.format(max_loss))\n",
    "        # print('AVG MSELoss: {}'.format(sum_loss / count_loss))\n",
    "\n",
    "        # print('MIN error: {} '.format(min_error))\n",
    "        # print('MAX error: {} '.format(max_error))\n",
    "        # print('AVG error: {}'.format(sum_error / count_error))\n",
    "        # print('MEAD error: {}'.format(np.median(errors)))\n",
    "\n",
    "    print('Accuracy : %d %%' % (100 * correct / total))\n",
    "    return test_dataset.__len__(), min_error, max_error, (sum_error / count_error), (np.median(errors)), errors\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_classifire_model(model, test_dataset, batch_size=50):\n",
    "    model.eval()  \n",
    "    \n",
    "    criterion = torch.nn.BCELoss().cuda()\n",
    "\n",
    "    print(\"CURRENT MODEL seq_len: {}\".format(test_dataset.seq_len))\n",
    "    print(\"CURRENT MODEL: {}\".format(model.__class__.__name__))\n",
    "    print(\"CURRENT DATASET SIZE: {}\".format(test_dataset.__len__()))\n",
    "    print(\"CURRENT NUM RECTS: {}\".format(num_rects))\n",
    "\n",
    "    test_loader = torch.utils.data.DataLoader(dataset=test_dataset,\n",
    "                                               batch_size=batch_size,\n",
    "                                               shuffle=True)\n",
    "\n",
    "    correct = 0\n",
    "    total = 0\n",
    "\n",
    "    min_loss = 999999\n",
    "    max_loss = 0\n",
    "    sum_loss = 0\n",
    "    count_loss = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for i, (eye_left, eye_right, face, pos) in enumerate(test_loader):\n",
    "            eye_left = eye_left.to(device)\n",
    "            eye_right = eye_right.to(device)\n",
    "            face = face.to(device)\n",
    "            pos = pos.to(device)\n",
    "\n",
    "            # Forward pass\n",
    "            out = model(eye_left, eye_right, face)\n",
    "            loss = criterion(out, pos)\n",
    "\n",
    "            _, predicted = torch.max(out.data, 1)\n",
    "            _, pos = torch.max(pos.data, 1)\n",
    "            total += pos.size(0)\n",
    "            \n",
    "            correct += (predicted == pos).sum().item()\n",
    "            if loss.item() < min_loss:\n",
    "                min_loss = loss.item()\n",
    "            if loss.item() > max_loss:\n",
    "                max_loss = loss.item()\n",
    "            sum_loss += loss.item()\n",
    "            count_loss += 1\n",
    "\n",
    "        \n",
    "        # print('MIN BCELoss: {} '.format(min_loss))\n",
    "        # print('MAX BCELoss: {} '.format(max_loss))\n",
    "        # print('AVG BCELoss: {}'.format(sum_loss / count_loss))\n",
    "        \n",
    "    print('Accuracy : %d %%' % (100 * correct / total))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_class_reg_model(model, classifier_model, test_dataset, batch_size=50, criterion=None, num_rects=4, screen_w=640, screen_h=480):\n",
    "    model.eval()\n",
    "    classifier_model.eval()\n",
    "\n",
    "    if criterion is None:\n",
    "        criterion = torch.nn.MSELoss().cuda()\n",
    "\n",
    "    print(\"CURRENT MODEL seq_len: {}\".format(test_dataset.seq_len))\n",
    "    print(\"CURRENT MODEL: {}\".format(model.__class__.__name__))\n",
    "    print(\"CURRENT DATASET SIZE: {}\".format(test_dataset.__len__()))\n",
    "    print(\"CURRENT NUM RECTS: {}\".format(num_rects))\n",
    "\n",
    "    test_loader = torch.utils.data.DataLoader(dataset=test_dataset,\n",
    "                                               batch_size=batch_size,\n",
    "                                               shuffle=True)\n",
    "\n",
    "    min_error = 999999\n",
    "    max_error = 0\n",
    "    sum_error = 0\n",
    "    count_error = 0\n",
    "    errors = np.zeros(test_dataset.__len__())\n",
    "\n",
    "    correct = 0\n",
    "    total = 0\n",
    "\n",
    "    min_loss = 999999\n",
    "    max_loss = 0\n",
    "    sum_loss = 0\n",
    "    count_loss = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for i, (eye_left, eye_right, face, pos) in enumerate(test_loader):\n",
    "            eye_left = eye_left.to(device)\n",
    "            eye_right = eye_right.to(device)\n",
    "            face = face.to(device)\n",
    "            pos = pos.to(device)\n",
    "\n",
    "            # Forward pass\n",
    "            classes = classifier_model(eye_left, eye_right, face)\n",
    "            out = model(eye_left, eye_right, face, classes)\n",
    "            pos = pos[:, -1, :]\n",
    "            loss = criterion(out, pos)\n",
    "\n",
    "            out = out.cpu().detach().numpy()\n",
    "            pos = pos.cpu().numpy()\n",
    "\n",
    "            for b in range(pos.shape[0]):\n",
    "                o = out[b]\n",
    "                p = pos[b]\n",
    "\n",
    "                error = math.sqrt((o[0] - p[0])**2 + (o[1] - p[1])**2)\n",
    "\n",
    "                if error < min_error:\n",
    "                    min_error = error\n",
    "                if error > max_error:\n",
    "                    max_error = error\n",
    "                sum_error += error\n",
    "\n",
    "                errors[count_error] = error\n",
    "\n",
    "                o_x = math.ceil((o[0]) / (screen_w / num_rects))\n",
    "                o_y = math.ceil((o[1]) / (screen_h / num_rects))\n",
    "\n",
    "                p_x = math.ceil((p[0]) / (screen_w / num_rects))\n",
    "                p_y = math.ceil((p[1]) / (screen_h / num_rects))\n",
    "\n",
    "                if ((p_y - 1) * num_rects + (p_x - 1)) == ((o_y - 1) * num_rects + (o_x - 1)):\n",
    "                    correct += 1\n",
    "\n",
    "                total += 1\n",
    "\n",
    "                count_error += 1\n",
    "\n",
    "            if loss.item() < min_loss:\n",
    "                min_loss = loss.item()\n",
    "            if loss.item() > max_loss:\n",
    "                max_loss = loss.item()\n",
    "            sum_loss += loss.item()\n",
    "            count_loss += 1\n",
    "\n",
    "        # print('MIN MSELoss: {} '.format(min_loss))\n",
    "        # print('MAX MSELoss: {} '.format(max_loss))\n",
    "        # print('AVG MSELoss: {}'.format(sum_loss / count_loss))\n",
    "\n",
    "        # print('MIN error: {} '.format(min_error))\n",
    "        # print('MAX error: {} '.format(max_error))\n",
    "        # print('AVG error: {}'.format(sum_error / count_error))\n",
    "        # print('MEAD error: {}'.format(np.median(errors)))\n",
    "\n",
    "    print('Accuracy : %d %%' % (100 * correct / total))\n",
    "    return test_dataset.__len__(), min_error, max_error, (sum_error / count_error), (np.median(errors)), errors\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "dataset_seq_len = 60\n",
    "\n",
    "batch_size = 10\n",
    "\n",
    "num_rects = 2\n",
    "seq_len = 2\n",
    "\n",
    "max_samples = 2500 \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LOAD MODEL: \n",
      "./models/TwoEyes/model_2500_1.pth\n",
      "FOUND MODEL\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "./test/60/\n",
      "1178\n",
      "LOADING DATA...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "END LOAD DATA\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000\n",
      "CURRENT MODEL seq_len: 1\n",
      "CURRENT MODEL: TwoEyes\n",
      "CURRENT DATASET SIZE: 1178\n",
      "CURRENT NUM RECTS: 2\n",
      "MIN MSELoss: 1500.035888671875 \n",
      "MAX MSELoss: 522216448.0 \n",
      "AVG MSELoss: 4465065.2758706305\n",
      "MIN error: 3.392680203847593 \n",
      "MAX error: 102197.27554067977 \n",
      "AVG error: 189.47455344374399\n",
      "MEAD error: 71.96442099467296\n",
      "Accuracy : 77 %\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(1178,\n",
       " 3.392680203847593,\n",
       " 102197.27554067977,\n",
       " 189.47455344374399,\n",
       " 71.96442099467296,\n",
       " array([ 47.69174718,  35.97276264, 168.46496604, ...,  93.9068467 ,\n",
       "         82.80579463, 100.30301667]))"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m = utility.load_model('./models/TwoEyes/model_{}_1.pth'.format(\n",
    "    max_samples), \n",
    "            device,\n",
    "            model.TwoEyes(seq_len=1))\n",
    "\n",
    "d = dataset.Dataset(seq_len=1, dirname='./test')\n",
    "\n",
    "test_reg_model(m, d, batch_size=batch_size, num_rects=num_rects)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LOAD MODEL: \n",
      "./models/TwoEyesLSTM/model_2500_2.pth\n",
      "FOUND MODEL\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "./test/60/\n",
      "1178\n",
      "LOADING DATA...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "END LOAD DATA\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000\n",
      "CURRENT MODEL seq_len: 2\n",
      "CURRENT MODEL: TwoEyesLSTM\n",
      "CURRENT DATASET SIZE: 1178\n",
      "CURRENT NUM RECTS: 2\n",
      "MIN MSELoss: 1309.87744140625 \n",
      "MAX MSELoss: 48682.671875 \n",
      "AVG MSELoss: 6459.758335954052\n",
      "MIN error: 0.7520375868500896 \n",
      "MAX error: 737.0507254881682 \n",
      "AVG error: 89.56623175440791\n",
      "MEAD error: 74.46454279325187\n",
      "Accuracy : 78 %\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(1178,\n",
       " 0.7520375868500896,\n",
       " 737.0507254881682,\n",
       " 89.56623175440791,\n",
       " 74.46454279325187,\n",
       " array([ 83.38160368,  56.92614089, 136.18959188, ...,  23.38799959,\n",
       "         41.56139044,  15.23365354]))"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m = utility.load_model('./models/TwoEyesLSTM/model_{}_{}.pth'.format(\n",
    "    max_samples, seq_len), \n",
    "            device,\n",
    "            model.TwoEyesLSTM(seq_len=seq_len))\n",
    "\n",
    "d = dataset.Dataset(seq_len=seq_len, dirname='./test')\n",
    "\n",
    "test_reg_model(m, d, batch_size=batch_size, num_rects=num_rects)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LOAD MODEL: \n",
      "./models/EyeClassifierLSTM/model_2500_4_2.pth\n",
      "FOUND MODEL\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "./test/60/\n",
      "1178\n",
      "LOADING DATA...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "[0. 0. 1. 0.]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "END LOAD DATA\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000\n",
      "[242. 273. 227. 259.]\n",
      "[284. 339. 260. 295.]\n",
      "CURRENT MODEL seq_len: 2\n",
      "CURRENT MODEL: EyeClassifierLSTM\n",
      "CURRENT DATASET SIZE: 1178\n",
      "CURRENT NUM RECTS: 2\n",
      "MIN BCELoss: 0.0024118521250784397 \n",
      "MAX BCELoss: 0.9510968327522278 \n",
      "AVG BCELoss: 0.3818675387705976\n",
      "Accuracy : 76 %\n"
     ]
    }
   ],
   "source": [
    "m = utility.load_model('./models/EyeClassifierLSTM/model_{}_{}_{}.pth'.format(\n",
    "    max_samples, num_rects * num_rects, seq_len), \n",
    "                           device,\n",
    "                           model.EyeClassifierLSTM(num_rects * num_rects, seq_len))\n",
    "\n",
    "d = dataset.CDataset(num_rects=num_rects, seq_len=seq_len, dirname='./test')\n",
    "\n",
    "test_classifire_model(m, d, batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LOAD MODEL: \n",
      "./models/EyeClassifierLSTM/model_2500_4_2.pth\n",
      "FOUND MODEL\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "./test/60/\n",
      "1178\n",
      "LOADING DATA...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LOAD MODEL: \n",
      "./models/EyesLSTMWithClassifier/model_2500_2_2.pth\n",
      "MODEL NOT FOUND\n",
      "0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "END LOAD DATA\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'NoneType' object has no attribute 'eval'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-47-0f384e2ebadd>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0md\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mseq_len\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mseq_len\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdirname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'./test'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m \u001b[0mtest_class_reg_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mm\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mc_m\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0md\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_rects\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnum_rects\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-7-8d311f174460>\u001b[0m in \u001b[0;36mtest_class_reg_model\u001b[0;34m(model, classifier_model, test_dataset, batch_size, criterion, num_rects, screen_w, screen_h)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mtest_class_reg_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclassifier_model\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_dataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m50\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_rects\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscreen_w\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m640\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscreen_h\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m480\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m     \u001b[0mclassifier_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mcriterion\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'eval'"
     ]
    }
   ],
   "source": [
    "c_m = utility.load_model('./models/EyeClassifierLSTM/model_{}_{}_{}.pth'.format(\n",
    "        max_samples, num_rects * num_rects, seq_len),\n",
    "        device,\n",
    "        model.EyeClassifierLSTM(num_rects * num_rects, seq_len))\n",
    "\n",
    "m = utility.load_model('./models/EyesLSTMWithClassifier/model_{}_{}_{}.pth'.format(\n",
    "    max_samples, seq_len, num_rects), \n",
    "            device,\n",
    "            model.EyesLSTMWithClassifier(seq_len=seq_len, num_rects=(num_rects * num_rects)))\n",
    "\n",
    "d = dataset.Dataset(seq_len=seq_len, dirname='./test')\n",
    "\n",
    "test_class_reg_model(m, c_m, d, batch_size=batch_size, num_rects=num_rects)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "./train/60/\n",
      "5\n",
      "LOADING DATA...\n",
      "END LOAD DATA\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "(3, 32, 32)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/byzilio/.local/lib/python3.6/site-packages/ipykernel_launcher.py:21: DeprecationWarning: `imsave` is deprecated!\n",
      "`imsave` is deprecated in SciPy 1.0.0, and will be removed in 1.2.0.\n",
      "Use ``imageio.imwrite`` instead.\n",
      "/home/byzilio/.local/lib/python3.6/site-packages/ipykernel_launcher.py:24: DeprecationWarning: `imsave` is deprecated!\n",
      "`imsave` is deprecated in SciPy 1.0.0, and will be removed in 1.2.0.\n",
      "Use ``imageio.imwrite`` instead.\n",
      "/home/byzilio/.local/lib/python3.6/site-packages/ipykernel_launcher.py:30: DeprecationWarning: `imsave` is deprecated!\n",
      "`imsave` is deprecated in SciPy 1.0.0, and will be removed in 1.2.0.\n",
      "Use ``imageio.imwrite`` instead.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7fe1fc89cbe0>"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import cv2\n",
    "import scipy.misc\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "d = dataset.Dataset(seq_len=8)\n",
    "print(d.eye_left[0][4].shape)\n",
    "img = d.eye_left[0][4].transpose(1, 2, 0)\n",
    "'''\n",
    "print(img.shape)\n",
    "print(d.eye_left[0][4] == img)\n",
    "i = np.zeros((32, 32 ,3))\n",
    "plt.imshow(img)\n",
    "for i in range (0, 4):\n",
    "    img = d.eye_left[0][i].transpose(1, 2, 0)\n",
    "    plt.figure()\n",
    "    plt.imshow(img)\n",
    "    \n",
    "'''  \n",
    "img = d.eye_left[0][0].transpose(1, 2, 0)\n",
    "scipy.misc.imsave('left_exapmle.png'.format(i), img)\n",
    "\n",
    "img = d.eye_right[0][0].transpose(1, 2, 0)\n",
    "scipy.misc.imsave('right_exapmle.png'.format(i), img)\n",
    "\n",
    "\n",
    "img = d.eye_left[0][0].transpose(1, 2, 0)\n",
    "img = np.concatenate((img, d.eye_right[0][1].transpose(1, 2, 0)), axis=1)\n",
    "scipy.misc.imsave('two_exapmle.png'.format(i), img)\n",
    "\n",
    "\n",
    "img = d.eye_left[0][0].transpose(1, 2, 0)\n",
    "img = np.concatenate((img, d.eye_left[0][1].transpose(1, 2, 0)), axis=1)\n",
    "img = np.concatenate((img, d.eye_left[0][2].transpose(1, 2, 0)), axis=1)\n",
    "img = np.concatenate((img, d.eye_left[0][3].transpose(1, 2, 0)), axis=1)\n",
    "scipy.misc.imsave('goritjopa.jpg'.format(i), img)\n",
    "plt.imshow(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
