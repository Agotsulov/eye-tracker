{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import model\n",
    "import torch\n",
    "import dataset\n",
    "import model\n",
    "import math\n",
    "import numpy as np\n",
    "import utility\n",
    "import os\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_reg_model(model, test_dataset, batch_size=50, criterion=None, num_rects=4, screen_w=640, screen_h=480):\n",
    "    model.eval()\n",
    "    \n",
    "    if criterion is None:\n",
    "        criterion = torch.nn.MSELoss().cuda()\n",
    "\n",
    "    print(\"CURRENT MODEL seq_len: {}\".format(test_dataset.seq_len))\n",
    "    print(\"CURRENT MODEL: {}\".format(model.__class__.__name__))\n",
    "    print(\"CURRENT DATASET SIZE: {}\".format(test_dataset.__len__()))\n",
    "    print(\"CURRENT NUM RECTS: {}\".format(num_rects))\n",
    "    \n",
    "    test_loader = torch.utils.data.DataLoader(dataset=test_dataset,\n",
    "                                               batch_size=batch_size,\n",
    "                                               shuffle=True)\n",
    "\n",
    "    min_error = 999999\n",
    "    max_error = 0\n",
    "    sum_error = 0\n",
    "    count_error = 0\n",
    "    errors = np.zeros(test_dataset.__len__())\n",
    "\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    \n",
    "    min_loss = 999999\n",
    "    max_loss = 0\n",
    "    sum_loss = 0\n",
    "    count_loss = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for i, (eye_left, eye_right, face, pos) in enumerate(test_loader):\n",
    "            eye_left = eye_left.to(device)\n",
    "            eye_right = eye_right.to(device)\n",
    "            face = face.to(device)\n",
    "            pos = pos.to(device)\n",
    "\n",
    "            # Forward pass\n",
    "            out = model(eye_left, eye_right, face)\n",
    "            pos = pos[:, -1, :]\n",
    "            loss = criterion(out, pos)\n",
    "\n",
    "            out = out.cpu().detach().numpy()\n",
    "            pos = pos.cpu().numpy()\n",
    "\n",
    "            for b in range(pos.shape[0]):\n",
    "                o = out[b]\n",
    "                p = pos[b]\n",
    "\n",
    "                o_x = math.ceil((o[0]) / (screen_w / num_rects))\n",
    "                o_y = math.ceil((o[1]) / (screen_h / num_rects))\n",
    "\n",
    "                p_x = math.ceil((p[0]) / (screen_w / num_rects))\n",
    "                p_y = math.ceil((p[1]) / (screen_h / num_rects))\n",
    "                \n",
    "                error = math.sqrt((o_x - p_x)**2 + (o_y - p_y)**2)\n",
    "\n",
    "                if error < min_error:\n",
    "                    min_error = error\n",
    "                if error > max_error:\n",
    "                    max_error = error\n",
    "                sum_error += error\n",
    "\n",
    "                errors[count_error] = error\n",
    "                \n",
    "            \n",
    "                \n",
    "                if ((p_y - 1) * num_rects + (p_x - 1)) == ((o_y - 1) * num_rects + (o_x - 1)):\n",
    "                    correct += 1\n",
    "                    \n",
    "                total += 1\n",
    "                \n",
    "                count_error += 1\n",
    "\n",
    "            if loss.item() < min_loss:\n",
    "                min_loss = loss.item()\n",
    "            if loss.item() > max_loss:\n",
    "                max_loss = loss.item()\n",
    "            sum_loss += loss.item()\n",
    "            count_loss += 1\n",
    "\n",
    "        # print('MIN MSELoss: {} '.format(min_loss))\n",
    "        # print('MAX MSELoss: {} '.format(max_loss))\n",
    "        # print('AVG MSELoss: {}'.format(sum_loss / count_loss))\n",
    "\n",
    "        print('MIN error: {} '.format(min_error))\n",
    "        print('MAX error: {} '.format(max_error))\n",
    "        print('AVG error: {}'.format(sum_error / count_error))\n",
    "        print('MEAD error: {}'.format(np.median(errors)))\n",
    "\n",
    "    print('Accuracy : %d %%' % (100 * correct / total))\n",
    "    return test_dataset.__len__(), min_error, max_error, (sum_error / count_error), (np.median(errors)), errors\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_classifire_model(model, test_dataset, batch_size=50):\n",
    "    model.eval()  \n",
    "    \n",
    "    criterion = torch.nn.BCELoss().cuda()\n",
    "\n",
    "    print(\"CURRENT MODEL seq_len: {}\".format(test_dataset.seq_len))\n",
    "    print(\"CURRENT MODEL: {}\".format(model.__class__.__name__))\n",
    "    print(\"CURRENT DATASET SIZE: {}\".format(test_dataset.__len__()))\n",
    "    print(\"CURRENT NUM RECTS: {}\".format(num_rects))\n",
    "\n",
    "    test_loader = torch.utils.data.DataLoader(dataset=test_dataset,\n",
    "                                               batch_size=batch_size,\n",
    "                                               shuffle=True)\n",
    "\n",
    "    correct = 0\n",
    "    total = 0\n",
    "\n",
    "    min_loss = 999999\n",
    "    max_loss = 0\n",
    "    sum_loss = 0\n",
    "    count_loss = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for i, (eye_left, eye_right, face, pos) in enumerate(test_loader):\n",
    "            eye_left = eye_left.to(device)\n",
    "            eye_right = eye_right.to(device)\n",
    "            face = face.to(device)\n",
    "            pos = pos.to(device)\n",
    "\n",
    "            # Forward pass\n",
    "            out = model(eye_left, eye_right, face)\n",
    "            loss = criterion(out, pos)\n",
    "\n",
    "            _, predicted = torch.max(out.data, 1)\n",
    "            _, pos = torch.max(pos.data, 1)\n",
    "            print(pos)\n",
    "            total += pos.size(0)\n",
    "            \n",
    "            correct += (predicted == pos).sum().item()\n",
    "            if loss.item() < min_loss:\n",
    "                min_loss = loss.item()\n",
    "            if loss.item() > max_loss:\n",
    "                max_loss = loss.item()\n",
    "            sum_loss += loss.item()\n",
    "            count_loss += 1\n",
    "\n",
    "        \n",
    "        # print('MIN BCELoss: {} '.format(min_loss))\n",
    "        # print('MAX BCELoss: {} '.format(max_loss))\n",
    "        # print('AVG BCELoss: {}'.format(sum_loss / count_loss))\n",
    "        \n",
    "    print('Accuracy : %d %%' % (100 * correct / total))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_class_reg_model(model, classifier_model, test_dataset, batch_size=50, criterion=None, num_rects=4, screen_w=640, screen_h=480):\n",
    "    model.eval()\n",
    "    classifier_model.eval()\n",
    "\n",
    "    if criterion is None:\n",
    "        criterion = torch.nn.MSELoss().cuda()\n",
    "\n",
    "    print(\"CURRENT MODEL seq_len: {}\".format(test_dataset.seq_len))\n",
    "    print(\"CURRENT MODEL: {}\".format(model.__class__.__name__))\n",
    "    print(\"CURRENT DATASET SIZE: {}\".format(test_dataset.__len__()))\n",
    "    print(\"CURRENT NUM RECTS: {}\".format(num_rects))\n",
    "\n",
    "    test_loader = torch.utils.data.DataLoader(dataset=test_dataset,\n",
    "                                               batch_size=batch_size,\n",
    "                                               shuffle=True)\n",
    "\n",
    "    min_error = 999999\n",
    "    max_error = 0\n",
    "    sum_error = 0\n",
    "    count_error = 0\n",
    "    errors = np.zeros(test_dataset.__len__())\n",
    "\n",
    "    correct = 0\n",
    "    total = 0\n",
    "\n",
    "    min_loss = 999999\n",
    "    max_loss = 0\n",
    "    sum_loss = 0\n",
    "    count_loss = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for i, (eye_left, eye_right, face, pos) in enumerate(test_loader):\n",
    "            eye_left = eye_left.to(device)\n",
    "            eye_right = eye_right.to(device)\n",
    "            face = face.to(device)\n",
    "            pos = pos.to(device)\n",
    "\n",
    "            # Forward pass\n",
    "            classes = classifier_model(eye_left, eye_right, face)\n",
    "            out = model(eye_left, eye_right, face, classes)\n",
    "            pos = pos[:, -1, :]\n",
    "            loss = criterion(out, pos)\n",
    "\n",
    "            out = out.cpu().detach().numpy()\n",
    "            pos = pos.cpu().numpy()\n",
    "\n",
    "            for b in range(pos.shape[0]):\n",
    "                o = out[b]\n",
    "                p = pos[b]\n",
    "\n",
    "                o_x = math.ceil((o[0]) / (screen_w / num_rects))\n",
    "                o_y = math.ceil((o[1]) / (screen_h / num_rects))\n",
    "\n",
    "                p_x = math.ceil((p[0]) / (screen_w / num_rects))\n",
    "                p_y = math.ceil((p[1]) / (screen_h / num_rects))\n",
    "                \n",
    "                error = math.sqrt((o_x - p_x)**2 + (o_y - p_y)**2)\n",
    "\n",
    "                if error < min_error:\n",
    "                    min_error = error\n",
    "                if error > max_error:\n",
    "                    max_error = error\n",
    "                sum_error += error\n",
    "\n",
    "                errors[count_error] = error\n",
    "                \n",
    "            \n",
    "                \n",
    "                if ((p_y - 1) * num_rects + (p_x - 1)) == ((o_y - 1) * num_rects + (o_x - 1)):\n",
    "                    correct += 1\n",
    "                    \n",
    "                total += 1\n",
    "                \n",
    "                count_error += 1\n",
    "\n",
    "            if loss.item() < min_loss:\n",
    "                min_loss = loss.item()\n",
    "            if loss.item() > max_loss:\n",
    "                max_loss = loss.item()\n",
    "            sum_loss += loss.item()\n",
    "            count_loss += 1\n",
    "\n",
    "        # print('MIN MSELoss: {} '.format(min_loss))\n",
    "        # print('MAX MSELoss: {} '.format(max_loss))\n",
    "        # print('AVG MSELoss: {}'.format(sum_loss / count_loss))\n",
    "\n",
    "        print('MIN error: {} '.format(min_error))\n",
    "        print('MAX error: {} '.format(max_error))\n",
    "        print('AVG error: {}'.format(sum_error / count_error))\n",
    "        print('MEDIAN error: {}'.format(np.median(errors)))\n",
    "\n",
    "    print('Accuracy : %d %%' % (100 * correct / total))\n",
    "    return test_dataset.__len__(), min_error, max_error, (sum_error / count_error), (np.median(errors)), errors\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "dataset_seq_len = 60\n",
    "\n",
    "batch_size = 10\n",
    "\n",
    "num_rects = 16\n",
    "seq_len = 8\n",
    "\n",
    "max_samples = 10770 \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "./test/60/\n",
      "1178\n",
      "LOADING DATA...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LOAD MODEL: \n",
      "./models/TwoEyes/model_10770_1.pth\n",
      "FOUND MODEL\n",
      "0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "END LOAD DATA\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000\n",
      "CURRENT MODEL seq_len: 1\n",
      "CURRENT MODEL: TwoEyes\n",
      "CURRENT DATASET SIZE: 1178\n",
      "CURRENT NUM RECTS: 32\n",
      "MIN error: 0.0 \n",
      "MAX error: 377992.1611515244 \n",
      "AVG error: 1407.1867207584205\n",
      "MEAD error: 4.123105625617661\n",
      "Accuracy : 0 %\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(1178,\n",
       " 0.0,\n",
       " 377992.1611515244,\n",
       " 1407.1867207584205,\n",
       " 4.123105625617661,\n",
       " array([3.00000000e+00, 3.16227766e+00, 1.00000000e+00, ...,\n",
       "        1.43129871e+03, 3.60555128e+00, 3.00000000e+00]))"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m = utility.load_model('./models/TwoEyes/model_{}_1.pth'.format(\n",
    "    max_samples), \n",
    "            device,\n",
    "            model.TwoEyes(seq_len=1))\n",
    "\n",
    "d = dataset.Dataset(seq_len=1, dirname='./test')\n",
    "\n",
    "test_reg_model(m, d, batch_size=batch_size, num_rects=num_rects)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LOAD MODEL: \n",
      "./models/TwoEyesLSTM/model_10770_8.pth\n",
      "FOUND MODEL\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "./test/60/\n",
      "1178\n",
      "LOADING DATA...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "END LOAD DATA\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000\n",
      "CURRENT MODEL seq_len: 8\n",
      "CURRENT MODEL: TwoEyesLSTM\n",
      "CURRENT DATASET SIZE: 1178\n",
      "CURRENT NUM RECTS: 32\n",
      "MIN error: 0.0 \n",
      "MAX error: 38.897300677553446 \n",
      "AVG error: 4.147414246712099\n",
      "MEAD error: 3.1622776601683795\n",
      "Accuracy : 1 %\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(1178,\n",
       " 0.0,\n",
       " 38.897300677553446,\n",
       " 4.147414246712099,\n",
       " 3.1622776601683795,\n",
       " array([ 3.16227766,  2.23606798,  5.09901951, ..., 14.86606875,\n",
       "         5.09901951,  5.83095189]))"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m = utility.load_model('./models/TwoEyesLSTM/model_{}_{}.pth'.format(\n",
    "    max_samples, seq_len), \n",
    "            device,\n",
    "            model.TwoEyesLSTM(seq_len=seq_len))\n",
    "\n",
    "d = dataset.Dataset(seq_len=seq_len, dirname='./test')\n",
    "\n",
    "test_reg_model(m, d, batch_size=batch_size, num_rects=num_rects)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = utility.load_model('./models/EyeClassifierLSTM/model_{}_{}_{}.pth'.format(\n",
    "    max_samples, num_rects * num_rects, seq_len), \n",
    "                           device,\n",
    "                           model.EyeClassifierLSTM(num_rects * num_rects, seq_len))\n",
    "\n",
    "d = dataset.CDataset(num_rects=num_rects, seq_len=seq_len, dirname='./test')\n",
    "\n",
    "test_classifire_model(m, d, batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LOAD MODEL: \n",
      "./models/EyeClassifierLSTM/model_10770_1024_8.pth\n",
      "FOUND MODEL\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "./test/60/\n",
      "1178\n",
      "LOADING DATA...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LOAD MODEL: \n",
      "./models/EyesLSTMWithClassifier/model_10770_8_32.pth\n",
      "MODEL NOT FOUND\n",
      "0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "END LOAD DATA\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'NoneType' object has no attribute 'eval'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-33-0f384e2ebadd>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0md\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mseq_len\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mseq_len\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdirname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'./test'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m \u001b[0mtest_class_reg_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mm\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mc_m\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0md\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_rects\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnum_rects\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-18-9bae46d9fef2>\u001b[0m in \u001b[0;36mtest_class_reg_model\u001b[0;34m(model, classifier_model, test_dataset, batch_size, criterion, num_rects, screen_w, screen_h)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mtest_class_reg_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclassifier_model\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_dataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m50\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_rects\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscreen_w\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m640\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscreen_h\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m480\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m     \u001b[0mclassifier_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mcriterion\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'eval'"
     ]
    }
   ],
   "source": [
    "c_m = utility.load_model('./models/EyeClassifierLSTM/model_{}_{}_{}.pth'.format(\n",
    "        max_samples, num_rects * num_rects, seq_len),\n",
    "        device,\n",
    "        model.EyeClassifierLSTM(num_rects * num_rects, seq_len))\n",
    "\n",
    "m = utility.load_model('./models/EyesLSTMWithClassifier/model_{}_{}_{}.pth'.format(\n",
    "    max_samples, seq_len, num_rects), \n",
    "            device,\n",
    "            model.EyesLSTMWithClassifier(seq_len=seq_len, num_rects=(num_rects * num_rects)))\n",
    "\n",
    "d = dataset.Dataset(seq_len=seq_len, dirname='./test')\n",
    "\n",
    "test_class_reg_model(m, c_m, d, batch_size=batch_size, num_rects=num_rects)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "import scipy.misc\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "d = dataset.Dataset(seq_len=8)\n",
    "print(d.eye_left[0][4].shape)\n",
    "img = d.eye_left[0][4].transpose(1, 2, 0)\n",
    "'''\n",
    "print(img.shape)\n",
    "print(d.eye_left[0][4] == img)\n",
    "i = np.zeros((32, 32 ,3))\n",
    "plt.imshow(img)\n",
    "for i in range (0, 4):\n",
    "    img = d.eye_left[0][i].transpose(1, 2, 0)\n",
    "    plt.figure()\n",
    "    plt.imshow(img)\n",
    "    \n",
    "'''  \n",
    "img = d.eye_left[0][0].transpose(1, 2, 0)\n",
    "scipy.misc.imsave('left_exapmle.png'.format(i), img)\n",
    "\n",
    "img = d.eye_right[0][0].transpose(1, 2, 0)\n",
    "scipy.misc.imsave('right_exapmle.png'.format(i), img)\n",
    "\n",
    "\n",
    "img = d.eye_left[0][0].transpose(1, 2, 0)\n",
    "img = np.concatenate((img, d.eye_right[0][1].transpose(1, 2, 0)), axis=1)\n",
    "scipy.misc.imsave('two_exapmle.png'.format(i), img)\n",
    "\n",
    "\n",
    "img = d.eye_left[0][0].transpose(1, 2, 0)\n",
    "img = np.concatenate((img, d.eye_left[0][1].transpose(1, 2, 0)), axis=1)\n",
    "img = np.concatenate((img, d.eye_left[0][2].transpose(1, 2, 0)), axis=1)\n",
    "img = np.concatenate((img, d.eye_left[0][3].transpose(1, 2, 0)), axis=1)\n",
    "scipy.misc.imsave('goritjopa.jpg'.format(i), img)\n",
    "plt.imshow(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
