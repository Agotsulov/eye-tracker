{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import model\n",
    "import torch\n",
    "import dataset\n",
    "import model\n",
    "import math\n",
    "import numpy as np\n",
    "import utility\n",
    "import os\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_reg_model(model, test_dataset, batch_size=50, criterion=None, num_rects=4, screen_w=640, screen_h=480):\n",
    "    model.eval()\n",
    "    \n",
    "    if criterion is None:\n",
    "        criterion = torch.nn.MSELoss().cuda()\n",
    "\n",
    "    print(\"CURRENT MODEL seq_len: {}\".format(test_dataset.seq_len))\n",
    "    print(\"CURRENT MODEL: {}\".format(model.__class__.__name__))\n",
    "    print(\"CURRENT DATASET SIZE: {}\".format(test_dataset.__len__()))\n",
    "    print(\"CURRENT NUM RECTS: {}\".format(num_rects))\n",
    "    \n",
    "    test_loader = torch.utils.data.DataLoader(dataset=test_dataset,\n",
    "                                               batch_size=batch_size,\n",
    "                                               shuffle=True)\n",
    "\n",
    "    min_error = 999999\n",
    "    max_error = 0\n",
    "    sum_error = 0\n",
    "    count_error = 0\n",
    "    errors = np.zeros(test_dataset.__len__())\n",
    "\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    \n",
    "    min_loss = 999999\n",
    "    max_loss = 0\n",
    "    sum_loss = 0\n",
    "    count_loss = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for i, (eye_left, eye_right, face, pos) in enumerate(test_loader):\n",
    "            eye_left = eye_left.to(device)\n",
    "            eye_right = eye_right.to(device)\n",
    "            face = face.to(device)\n",
    "            pos = pos.to(device)\n",
    "\n",
    "            # Forward pass\n",
    "            out = model(eye_left, eye_right, face)\n",
    "            pos = pos[:, -1, :]\n",
    "            loss = criterion(out, pos)\n",
    "\n",
    "            out = out.cpu().detach().numpy()\n",
    "            pos = pos.cpu().numpy()\n",
    "\n",
    "            for b in range(pos.shape[0]):\n",
    "                o = out[b]\n",
    "                p = pos[b]\n",
    "\n",
    "                o_x = math.ceil((o[0]) / (screen_w / num_rects))\n",
    "                o_y = math.ceil((o[1]) / (screen_h / num_rects))\n",
    "\n",
    "                p_x = math.ceil((p[0]) / (screen_w / num_rects))\n",
    "                p_y = math.ceil((p[1]) / (screen_h / num_rects))\n",
    "                \n",
    "                error = math.sqrt((o_x - p_x)**2 + (o_y - p_y)**2)\n",
    "\n",
    "                if error < min_error:\n",
    "                    min_error = error\n",
    "                if error > max_error:\n",
    "                    max_error = error\n",
    "                sum_error += error\n",
    "\n",
    "                errors[count_error] = error\n",
    "                \n",
    "            \n",
    "                \n",
    "                if ((p_y - 1) * num_rects + (p_x - 1)) == ((o_y - 1) * num_rects + (o_x - 1)):\n",
    "                    correct += 1\n",
    "                    \n",
    "                total += 1\n",
    "                \n",
    "                count_error += 1\n",
    "\n",
    "            if loss.item() < min_loss:\n",
    "                min_loss = loss.item()\n",
    "            if loss.item() > max_loss:\n",
    "                max_loss = loss.item()\n",
    "            sum_loss += loss.item()\n",
    "            count_loss += 1\n",
    "\n",
    "        # print('MIN MSELoss: {} '.format(min_loss))\n",
    "        # print('MAX MSELoss: {} '.format(max_loss))\n",
    "        # print('AVG MSELoss: {}'.format(sum_loss / count_loss))\n",
    "\n",
    "        print('MIN error: {} '.format(min_error))\n",
    "        print('MAX error: {} '.format(max_error))\n",
    "        print('AVG error: {}'.format(sum_error / count_error))\n",
    "        print('MEAD error: {}'.format(np.median(errors)))\n",
    "\n",
    "    print('Accuracy : %d %%' % (100 * correct / total))\n",
    "    return test_dataset.__len__(), min_error, max_error, (sum_error / count_error), (np.median(errors)), errors\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_classifire_model(model, test_dataset, batch_size=50):\n",
    "    model.eval()  \n",
    "    \n",
    "    criterion = torch.nn.BCELoss().cuda()\n",
    "\n",
    "    print(\"CURRENT MODEL seq_len: {}\".format(test_dataset.seq_len))\n",
    "    print(\"CURRENT MODEL: {}\".format(model.__class__.__name__))\n",
    "    print(\"CURRENT DATASET SIZE: {}\".format(test_dataset.__len__()))\n",
    "    print(\"CURRENT NUM RECTS: {}\".format(num_rects))\n",
    "\n",
    "    test_loader = torch.utils.data.DataLoader(dataset=test_dataset,\n",
    "                                               batch_size=batch_size,\n",
    "                                               shuffle=True)\n",
    "\n",
    "    correct = 0\n",
    "    total = 0\n",
    "\n",
    "    min_loss = 999999\n",
    "    max_loss = 0\n",
    "    sum_loss = 0\n",
    "    count_loss = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for i, (eye_left, eye_right, face, pos) in enumerate(test_loader):\n",
    "            eye_left = eye_left.to(device)\n",
    "            eye_right = eye_right.to(device)\n",
    "            face = face.to(device)\n",
    "            pos = pos.to(device)\n",
    "\n",
    "            # Forward pass\n",
    "            out = model(eye_left, eye_right, face)\n",
    "            loss = criterion(out, pos)\n",
    "\n",
    "            _, predicted = torch.max(out.data, 1)\n",
    "            _, pos = torch.max(pos.data, 1)\n",
    "            print(pos)\n",
    "            total += pos.size(0)\n",
    "            \n",
    "            correct += (predicted == pos).sum().item()\n",
    "            if loss.item() < min_loss:\n",
    "                min_loss = loss.item()\n",
    "            if loss.item() > max_loss:\n",
    "                max_loss = loss.item()\n",
    "            sum_loss += loss.item()\n",
    "            count_loss += 1\n",
    "\n",
    "        \n",
    "        # print('MIN BCELoss: {} '.format(min_loss))\n",
    "        # print('MAX BCELoss: {} '.format(max_loss))\n",
    "        # print('AVG BCELoss: {}'.format(sum_loss / count_loss))\n",
    "        \n",
    "    print('Accuracy : %d %%' % (100 * correct / total))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_class_reg_model(model, classifier_model, test_dataset, batch_size=50, criterion=None, num_rects=4, screen_w=640, screen_h=480):\n",
    "    model.eval()\n",
    "    classifier_model.eval()\n",
    "\n",
    "    if criterion is None:\n",
    "        criterion = torch.nn.MSELoss().cuda()\n",
    "\n",
    "    print(\"CURRENT MODEL seq_len: {}\".format(test_dataset.seq_len))\n",
    "    print(\"CURRENT MODEL: {}\".format(model.__class__.__name__))\n",
    "    print(\"CURRENT DATASET SIZE: {}\".format(test_dataset.__len__()))\n",
    "    print(\"CURRENT NUM RECTS: {}\".format(num_rects))\n",
    "\n",
    "    test_loader = torch.utils.data.DataLoader(dataset=test_dataset,\n",
    "                                               batch_size=batch_size,\n",
    "                                               shuffle=True)\n",
    "\n",
    "    min_error = 999999\n",
    "    max_error = 0\n",
    "    sum_error = 0\n",
    "    count_error = 0\n",
    "    errors = np.zeros(test_dataset.__len__())\n",
    "\n",
    "    correct = 0\n",
    "    total = 0\n",
    "\n",
    "    min_loss = 999999\n",
    "    max_loss = 0\n",
    "    sum_loss = 0\n",
    "    count_loss = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for i, (eye_left, eye_right, face, pos) in enumerate(test_loader):\n",
    "            eye_left = eye_left.to(device)\n",
    "            eye_right = eye_right.to(device)\n",
    "            face = face.to(device)\n",
    "            pos = pos.to(device)\n",
    "\n",
    "            # Forward pass\n",
    "            classes = classifier_model(eye_left, eye_right, face)\n",
    "            out = model(eye_left, eye_right, face, classes)\n",
    "            pos = pos[:, -1, :]\n",
    "            loss = criterion(out, pos)\n",
    "\n",
    "            out = out.cpu().detach().numpy()\n",
    "            pos = pos.cpu().numpy()\n",
    "\n",
    "            for b in range(pos.shape[0]):\n",
    "                o = out[b]\n",
    "                p = pos[b]\n",
    "\n",
    "                o_x = math.ceil((o[0]) / (screen_w / num_rects))\n",
    "                o_y = math.ceil((o[1]) / (screen_h / num_rects))\n",
    "\n",
    "                p_x = math.ceil((p[0]) / (screen_w / num_rects))\n",
    "                p_y = math.ceil((p[1]) / (screen_h / num_rects))\n",
    "                \n",
    "                error = math.sqrt((o_x - p_x)**2 + (o_y - p_y)**2)\n",
    "\n",
    "                if error < min_error:\n",
    "                    min_error = error\n",
    "                if error > max_error:\n",
    "                    max_error = error\n",
    "                sum_error += error\n",
    "\n",
    "                errors[count_error] = error\n",
    "                \n",
    "            \n",
    "                \n",
    "                if ((p_y - 1) * num_rects + (p_x - 1)) == ((o_y - 1) * num_rects + (o_x - 1)):\n",
    "                    correct += 1\n",
    "                    \n",
    "                total += 1\n",
    "                \n",
    "                count_error += 1\n",
    "\n",
    "            if loss.item() < min_loss:\n",
    "                min_loss = loss.item()\n",
    "            if loss.item() > max_loss:\n",
    "                max_loss = loss.item()\n",
    "            sum_loss += loss.item()\n",
    "            count_loss += 1\n",
    "\n",
    "        # print('MIN MSELoss: {} '.format(min_loss))\n",
    "        # print('MAX MSELoss: {} '.format(max_loss))\n",
    "        # print('AVG MSELoss: {}'.format(sum_loss / count_loss))\n",
    "\n",
    "        print('MIN error: {} '.format(min_error))\n",
    "        print('MAX error: {} '.format(max_error))\n",
    "        print('AVG error: {}'.format(sum_error / count_error))\n",
    "        print('MEDIAN error: {}'.format(np.median(errors)))\n",
    "\n",
    "    print('Accuracy : %d %%' % (100 * correct / total))\n",
    "    return test_dataset.__len__(), min_error, max_error, (sum_error / count_error), (np.median(errors)), errors\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "dataset_seq_len = 60\n",
    "\n",
    "batch_size = 10\n",
    "\n",
    "num_rects = 16\n",
    "seq_len = 8\n",
    "\n",
    "max_samples = 10770 \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "./test/60/\n",
      "1178\n",
      "LOADING DATA...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LOAD MODEL: \n",
      "./models/TwoEyes/model_10770_1.pth\n",
      "FOUND MODEL\n",
      "0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "END LOAD DATA\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000\n",
      "CURRENT MODEL seq_len: 1\n",
      "CURRENT MODEL: TwoEyes\n",
      "CURRENT DATASET SIZE: 1178\n",
      "CURRENT NUM RECTS: 16\n",
      "MIN error: 0.0 \n",
      "MAX error: 188996.0805757622 \n",
      "AVG error: 703.5967326836037\n",
      "MEAD error: 2.23606797749979\n",
      "Accuracy : 5 %\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(1178,\n",
       " 0.0,\n",
       " 188996.0805757622,\n",
       " 703.5967326836037,\n",
       " 2.23606797749979,\n",
       " array([1.        , 1.41421356, 1.        , ..., 1.41421356, 3.60555128,\n",
       "        0.        ]))"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m = utility.load_model('./models/TwoEyes/model_{}_1.pth'.format(\n",
    "    max_samples), \n",
    "            device,\n",
    "            model.TwoEyes(seq_len=1))\n",
    "\n",
    "d = dataset.Dataset(seq_len=1, dirname='./test')\n",
    "\n",
    "test_reg_model(m, d, batch_size=batch_size, num_rects=num_rects)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LOAD MODEL: \n",
      "./models/TwoEyesLSTM/model_10770_8.pth\n",
      "FOUND MODEL\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "./test/60/\n",
      "1178\n",
      "LOADING DATA...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "END LOAD DATA\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000\n",
      "CURRENT MODEL seq_len: 8\n",
      "CURRENT MODEL: TwoEyesLSTM\n",
      "CURRENT DATASET SIZE: 1178\n",
      "CURRENT NUM RECTS: 16\n",
      "MIN error: 0.0 \n",
      "MAX error: 19.1049731745428 \n",
      "AVG error: 2.1026770784247817\n",
      "MEAD error: 1.4142135623730951\n",
      "Accuracy : 8 %\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(1178,\n",
       " 0.0,\n",
       " 19.1049731745428,\n",
       " 2.1026770784247817,\n",
       " 1.4142135623730951,\n",
       " array([1.41421356, 2.82842712, 3.        , ..., 2.        , 3.16227766,\n",
       "        1.41421356]))"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m = utility.load_model('./models/TwoEyesLSTM/model_{}_{}.pth'.format(\n",
    "    max_samples, seq_len), \n",
    "            device,\n",
    "            model.TwoEyesLSTM(seq_len=seq_len))\n",
    "\n",
    "d = dataset.Dataset(seq_len=seq_len, dirname='./test')\n",
    "\n",
    "test_reg_model(m, d, batch_size=batch_size, num_rects=num_rects)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = utility.load_model('./models/EyeClassifierLSTM/model_{}_{}_{}.pth'.format(\n",
    "    max_samples, num_rects * num_rects, seq_len), \n",
    "                           device,\n",
    "                           model.EyeClassifierLSTM(num_rects * num_rects, seq_len))\n",
    "\n",
    "d = dataset.CDataset(num_rects=num_rects, seq_len=seq_len, dirname='./test')\n",
    "\n",
    "test_classifire_model(m, d, batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LOAD MODEL: \n",
      "./models/EyeClassifierLSTM/model_10770_256_8.pth\n",
      "FOUND MODEL\n",
      "LOAD MODEL: \n",
      "./models/EyesLSTMWithClassifier/model_10770_8_16.pth\n",
      "FOUND MODEL\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "./test/60/\n",
      "1178\n",
      "LOADING DATA...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "END LOAD DATA\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000\n",
      "CURRENT MODEL seq_len: 8\n",
      "CURRENT MODEL: EyesLSTMWithClassifier\n",
      "CURRENT DATASET SIZE: 1178\n",
      "CURRENT NUM RECTS: 16\n",
      "MIN error: 0.0 \n",
      "MAX error: 190.5465822312224 \n",
      "AVG error: 2.227015535640416\n",
      "MEDIAN error: 1.4142135623730951\n",
      "Accuracy : 13 %\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(1178,\n",
       " 0.0,\n",
       " 190.5465822312224,\n",
       " 2.227015535640416,\n",
       " 1.4142135623730951,\n",
       " array([0.        , 1.        , 7.61577311, ..., 0.        , 2.23606798,\n",
       "        2.82842712]))"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c_m = utility.load_model('./models/EyeClassifierLSTM/model_{}_{}_{}.pth'.format(\n",
    "        max_samples, num_rects * num_rects, seq_len),\n",
    "        device,\n",
    "        model.EyeClassifierLSTM(num_rects * num_rects, seq_len))\n",
    "\n",
    "m = utility.load_model('./models/EyesLSTMWithClassifier/model_{}_{}_{}.pth'.format(\n",
    "    max_samples, seq_len, num_rects), \n",
    "            device,\n",
    "            model.EyesLSTMWithClassifier(seq_len=seq_len, num_rects=(num_rects * num_rects)))\n",
    "\n",
    "d = dataset.Dataset(seq_len=seq_len, dirname='./test')\n",
    "\n",
    "test_class_reg_model(m, c_m, d, batch_size=batch_size, num_rects=num_rects)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "import scipy.misc\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "d = dataset.Dataset(seq_len=8)\n",
    "print(d.eye_left[0][4].shape)\n",
    "img = d.eye_left[0][4].transpose(1, 2, 0)\n",
    "'''\n",
    "print(img.shape)\n",
    "print(d.eye_left[0][4] == img)\n",
    "i = np.zeros((32, 32 ,3))\n",
    "plt.imshow(img)\n",
    "for i in range (0, 4):\n",
    "    img = d.eye_left[0][i].transpose(1, 2, 0)\n",
    "    plt.figure()\n",
    "    plt.imshow(img)\n",
    "    \n",
    "'''  \n",
    "img = d.eye_left[0][0].transpose(1, 2, 0)\n",
    "scipy.misc.imsave('left_exapmle.png'.format(i), img)\n",
    "\n",
    "img = d.eye_right[0][0].transpose(1, 2, 0)\n",
    "scipy.misc.imsave('right_exapmle.png'.format(i), img)\n",
    "\n",
    "\n",
    "img = d.eye_left[0][0].transpose(1, 2, 0)\n",
    "img = np.concatenate((img, d.eye_right[0][1].transpose(1, 2, 0)), axis=1)\n",
    "scipy.misc.imsave('two_exapmle.png'.format(i), img)\n",
    "\n",
    "\n",
    "img = d.eye_left[0][0].transpose(1, 2, 0)\n",
    "img = np.concatenate((img, d.eye_left[0][1].transpose(1, 2, 0)), axis=1)\n",
    "img = np.concatenate((img, d.eye_left[0][2].transpose(1, 2, 0)), axis=1)\n",
    "img = np.concatenate((img, d.eye_left[0][3].transpose(1, 2, 0)), axis=1)\n",
    "scipy.misc.imsave('goritjopa.jpg'.format(i), img)\n",
    "plt.imshow(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
